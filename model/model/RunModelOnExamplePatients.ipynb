{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takes a sample of patients, extracts  and runs the stored POC model on them, then writes results to hdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import datetime as datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from impala.util import as_pandas\n",
    "from sklearn.externals import joblib\n",
    "import cPickle as pickle\n",
    "%matplotlib notebook\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from impala.dbapi import connect\n",
    "conn = connect(host=\"mycluster.domain.com\", port=my_impala_port_number)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"use my_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pull_and_writedata_2query(masterdf, i, timeoffset):\n",
    "    '''\n",
    "    Input: masterdf to write,  index, timeoffset in hours\n",
    "    returns: masterdf with row values filled out\n",
    "    '''\n",
    "    enc = masterdf.encntr_id.iloc[i]\n",
    "    timestart = masterdf.encntr_starttime.iloc[i] + timeoffset*3600*1000\n",
    "    timeend = timestart + 12*3600*1000\n",
    "    age = masterdf.age.iloc[i]\n",
    "    \n",
    "    query = '''\n",
    "    SELECT ce.encntr_id, ce.event_cd \n",
    "    ,cv_event_cd.description AS event_description\n",
    "    ,ce.event_end_dt_tm AS unix_event_end_tm \n",
    "    , ce.result_val, ce.result_units_cd\n",
    "    ,tc.checkin_dt_tm AS checkin_time\n",
    "    FROM clinical_event ce \n",
    "    JOIN encounter enc ON enc.encntr_id = ce.encntr_id\n",
    "    JOIN tracking_item ti ON enc.encntr_id = ti.encntr_id\n",
    "    JOIN tracking_checkin tc ON tc.tracking_id = ti.tracking_id\n",
    "    LEFT OUTER JOIN code_value   cv_event_cd \n",
    "    ON   ce.event_cd           = cv_event_cd.code_value     \n",
    "    WHERE ce.encntr_id = '{0}' \n",
    "    AND ce.event_end_dt_tm < {1} \n",
    "    AND ce.result_status_cd NOT IN ('31', '36')\n",
    "    AND ce.event_class_cd NOT IN ('654645')\n",
    "    AND ce.valid_until_dt_tm > 4e12\n",
    "    AND ce.event_cd IN ('679984', '2797130','2798305', '703306', '703501', '703511', '703516', \n",
    "    '703540', '703558', '2700653',\n",
    "    '3623994', '4674677', '4686698', '679984', '2797130','2798305', '2797129', '75144985',\n",
    "    '54411998', '2700653', '4674677', '3618608', '186470117') \n",
    "    ORDER BY ce.encntr_id, ce.performed_dt_tm;\n",
    "    '''.format(enc, timeend)\n",
    "    \n",
    "    cur.execute(query)\n",
    "    df = as_pandas(cur)\n",
    "    df['result_val'] = pd.to_numeric(df.result_val, errors = 'coerce')\n",
    "\n",
    "    df_timebox = df[df['unix_event_end_tm']>timestart]\n",
    "    \n",
    "    pairs = [('DBP', '703516'), ('SBP', '703501'),\n",
    "          ('MAP', '703306'), ('temp', '703558'), ('RR', '703540'),\n",
    "          ('SPO2', '3623994'), ('pulse', '703511') ]\n",
    "\n",
    "    for pair in pairs:       \n",
    "        if (df_timebox[df_timebox['event_cd']==pair[1]]).empty: # df with this event code is empty\n",
    "            masterdf.ix[i, pair[0]+\"_mean\"] = np.nan\n",
    "            masterdf.ix[i, pair[0]+\"_recent\"] = np.nan\n",
    "        else:\n",
    "            masterdf.ix[i, pair[0]+\"_mean\"] = df_timebox[df_timebox['event_cd']==pair[1]]['result_val'].mean()\n",
    "            masterdf.ix[i, pair[0]+\"_recent\"] = df_timebox[df_timebox['event_cd']==pair[1]\n",
    "                                                  ].sort_values(by='unix_event_end_tm', ascending=False).iloc[0]['result_val']\n",
    "    \n",
    "    if (df[df['event_cd']=='679984']).empty: \n",
    "        masterdf.ix[i, 'on_iv'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'on_iv'] = 1\n",
    "        \n",
    "    if ( (df[df['event_cd']=='2797130']).empty &\n",
    "         (df[df['event_cd']=='2798305']).empty &\n",
    "         (df[df['event_cd']=='2797129']).empty ):\n",
    "        masterdf.ix[i, 'bu-nal'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'bu-nal'] = 1\n",
    "        \n",
    "    if df[df['event_cd']=='186470117'].empty:\n",
    "        masterdf.ix[i, 'dialysis'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'dialysis'] = 1\n",
    "        \n",
    "    # smoking status - binary, 0 for nonsmoker/former smoker /unknown, 1 for smoker\n",
    "    # assuming if more than 1 of these smoking lines exist, they will say the same thing.\n",
    "    if (df[df.event_cd=='75144985']).empty:\n",
    "        masterdf.ix[i, 'smoker'] = 0\n",
    "    elif ( (df[df.event_cd=='75144985'].result_val.get_values()[0] == 'Heavy tobacco smoker') | \n",
    "     (df[df.event_cd=='75144985'].result_val.get_values()[0] == 'Light tobacco smoker') |\n",
    "     (df[df.event_cd=='75144985'].result_val.get_values()[0] == 'Current every day smoker') |\n",
    "     (df[df.event_cd=='75144985'].result_val.get_values()[0] == 'Current some day smoker') |\n",
    "     (df[df.event_cd=='75144985'].result_val.get_values()[0] == 'Smoker, current status unknown')  ):\n",
    "        masterdf.ix[i, 'smoker'] = 1\n",
    "    else: \n",
    "        masterdf.ix[i, 'smoker'] = 0\n",
    "        \n",
    "    # previous RRT event\n",
    "    if (df[df.event_cd=='54411998']).empty:\n",
    "        masterdf.ix[i, 'prev_rrt'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'prev_rrt'] = 1\n",
    "        \n",
    "    # Obesity status\n",
    "    if (df[df['event_cd']=='2700653']).empty:\n",
    "        masterdf.ix[i, 'obese'] = np.nan\n",
    "    elif (df[df['event_cd']=='4674677']).empty: \n",
    "        masterdf.ix[i, 'obese'] = np.nan\n",
    "    else:\n",
    "        # assuming there won't be much variation -- grab first value from both of height & weight\n",
    "        height = pd.to_numeric(df[df['event_cd']=='2700653']['result_val'].get_values())[0]\n",
    "        if df[df['event_cd']=='2700653']['result_units_cd'].get_values()[0] == '267':\n",
    "            # convert inch -> cm\n",
    "            height = height * 2.54\n",
    "        height = height/100.0  # convert to get height in m\n",
    "        weight = pd.to_numeric(df[df['event_cd']=='4674677']['result_val'].get_values())[0]\n",
    "        bmi = weight / (height*height)\n",
    "        if (bmi>30) & (age>19):\n",
    "            masterdf.ix[i, 'obese'] = 1\n",
    "        else:\n",
    "            masterdf.ix[i, 'obese'] = 0\n",
    "          \n",
    "    \n",
    "    # querying orders for medications\n",
    "    query_ords = '''SELECT ords.encntr_id, mdx.multum_category_id, orig_order_dt_tm\n",
    "    FROM (SELECT encntr_id, cki, substr(cki,9) as cki_id, order_id, orig_order_dt_tm FROM orders) ords \n",
    "    LEFT OUTER JOIN mltm_category_drug_xref mdx ON ords.cki_id = mdx.drug_identifier \n",
    "    LEFT OUTER JOIN mltm_drug_categories mdc ON mdc.multum_category_id = mdx.multum_category_id \n",
    "    WHERE mdx.multum_category_id IN ('261', '262','285', '283', '60', '191', '77', '210', '251', '341', '20', '21', \n",
    "                                   '22', '23', '24', '25', '26') \n",
    "    AND ords.encntr_id = '{0}'\n",
    "    AND ords.orig_order_dt_tm < {1} \n",
    "    ;'''.format(enc, timeend)\n",
    "    \n",
    "    cur.execute(query_ords)\n",
    "    df_ords = as_pandas(cur)\n",
    "    \n",
    "    if df_ords[(df_ords['multum_category_id']=='261') | (df_ords['multum_category_id']=='262') \n",
    "        | (df_ords['multum_category_id']=='283') | (df_ords['multum_category_id']=='285') ].empty:\n",
    "        masterdf.ix[i, 'anticoagulants'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'anticoagulants'] = 1\n",
    "\n",
    "    if (df_ords[df_ords['multum_category_id']=='60']).empty: # df with this event code is empty\n",
    "        masterdf.ix[i, 'narcotics'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'narcotics'] = 1\n",
    "\n",
    "    if (df_ords[df_ords['multum_category_id']=='191']).empty: # df with this event code is empty\n",
    "        masterdf.ix[i, 'narc-ans'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'narc-ans'] = 1\n",
    "\n",
    "    if df_ords[ (df_ords['multum_category_id']=='77') | (df_ords['multum_category_id']=='210') \n",
    "        | (df_ords['multum_category_id']=='251') | (df_ords['multum_category_id']=='341') ].empty:\n",
    "        masterdf.ix[i, 'antipsychotics'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'antipsychotics'] = 1\n",
    "\n",
    "    if df_ords[ (df_ords['multum_category_id']=='20') | (df_ords['multum_category_id']=='21') \n",
    "        | (df_ords['multum_category_id']=='22') | (df_ords['multum_category_id']=='23') \n",
    "        | (df_ords['multum_category_id']=='24') | (df_ords['multum_category_id']=='25')\n",
    "        | (df_ords['multum_category_id']=='26') ].empty:\n",
    "        masterdf.ix[i, 'chemo'] = 0\n",
    "    else:\n",
    "        masterdf.ix[i, 'chemo'] = 1\n",
    "        \n",
    "    return masterdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull encounter ids, encounter start times, patient info for the right kind of patients from the right hospital who have stays > 36 hours\n",
    "# using encounter arrive time rather than tc.checkin_dt_tm -- tc.checkin_dt_tm may have multiple values per checkin time.\n",
    "\n",
    "query = '''\n",
    "SELECT enc.encntr_id\n",
    ", enc.arrive_dt_tm as encntr_starttime\n",
    ", (enc.depart_dt_tm - enc.arrive_dt_tm)/3600000 as encntr_duration_hrs\n",
    ", enc.depart_dt_tm as encntr_endtime\n",
    ", from_unixtime(CAST(enc.encntr_complete_dt_tm/1000 as bigint)) AS encntr_complete_time\n",
    ", year(now()) - year(from_unixtime(CAST(p.birth_dt_tm/1000 as bigint))) AS age \n",
    ", CASE p.sex_cd WHEN '362' then 'F' ELSE 'M' END as sex\n",
    ", cvr.description as race\n",
    "FROM encounter enc\n",
    "INNER JOIN person p on p.person_id = enc.person_id\n",
    "LEFT OUTER JOIN code_value cvr ON cvr.code_value = p.race_cd\n",
    "WHERE enc.depart_dt_tm - enc.arrive_dt_tm > 3600*1000*36\n",
    "AND enc.admit_type_cd != '0'\n",
    "AND enc.encntr_type_class_cd = '391'\n",
    "AND enc.loc_facility_cd='633867'\n",
    "AND enc.encntr_complete_dt_tm < 4e12\n",
    "ORDER BY enc.depart_dt_tm DESC\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "cur.execute(query)\n",
    "dfshell = as_pandas(cur)\n",
    "\n",
    "col_list = [ 'encntr_id', 'encntr_starttime', 'encntr_duration_hrs', 'encntr_endtime', 'encntr_complete_time',\n",
    "            'age', 'sex', 'race', 'obese', 'smoker', 'prev_rrt', 'on_iv', 'bu-nal',\n",
    "           'DBP_mean', 'DBP_recent', 'SBP_mean', 'SBP_recent', \n",
    "            'MAP_mean', 'MAP_recent', \n",
    "             'temp_mean', 'temp_recent', 'SPO2_mean', 'SPO2_recent',\n",
    "            'RR_mean', 'RR_recent', 'pulse_mean', 'pulse_recent',\n",
    "            'anticoagulants', 'narcotics', 'narc-ans',\n",
    "            'antipsychotics', 'chemo', 'dialysis']\n",
    "\n",
    "dfshell = dfshell.reindex(columns=col_list)\n",
    "dfshell['age'] = pd.to_numeric(dfshell.age, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfshell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeltable1 = dfshell.copy() # hours 0 - 12\n",
    "modeltable2 = dfshell.copy() # hours 12 - 24\n",
    "modeltable3 = dfshell.copy() # hours 24 - 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in xrange(len(modeltable1)):\n",
    "# for i in xrange(1):\n",
    "    count += 1\n",
    "    print \"On loop: {0} of {1}\".format(count, len(modeltable1))\n",
    "    modeltable1 = pull_and_writedata_2query(modeltable1, i, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in xrange(len(modeltable2)):\n",
    "# for i in xrange(1):\n",
    "    count += 1\n",
    "    print \"On loop: {0} of {1}\".format(count, len(modeltable2))\n",
    "    modeltable2 = pull_and_writedata_2query(modeltable2, i, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in xrange(len(modeltable3)):\n",
    "# for i in xrange(1):\n",
    "    count += 1\n",
    "    print \"On loop: {0} of {1}\".format(count, len(modeltable3))\n",
    "    modeltable3 = pull_and_writedata_2query(modeltable3, i, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modeltable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modeltable2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modeltable3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset columns & predict for each modelingtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# binarize sex\n",
    "modeltable1['is_male'] = modeltable1['sex'].map({'M': 1, 'F': 0})\n",
    "modeltable1.pop('sex')\n",
    "modeltable2['is_male'] = modeltable2['sex'].map({'M': 1, 'F': 0})\n",
    "modeltable2.pop('sex')\n",
    "modeltable3['is_male'] = modeltable3['sex'].map({'M': 1, 'F': 0})\n",
    "modeltable3.pop('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_use = [ 'age', 'is_male', 'obese', 'smoker', 'prev_rrt', 'on_iv', 'bu-nal',\n",
    "           'DBP_mean', 'DBP_recent', 'SBP_mean', 'SBP_recent', \n",
    "            'MAP_mean', 'MAP_recent', \n",
    "             'temp_mean', 'temp_recent', 'SPO2_mean', 'SPO2_recent',\n",
    "            'RR_mean', 'RR_recent', 'pulse_mean', 'pulse_recent',\n",
    "            'anticoagulants', 'narcotics', 'narc-ans',\n",
    "            'antipsychotics', 'chemo', 'dialysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = modeltable1[col_use]\n",
    "X2 = modeltable2[col_use]\n",
    "X3 = modeltable3[col_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's look at getting rid of the data rows where vitals signs are all nans\n",
    "vitals_cols = ['DBP_mean', 'DBP_recent', # take the mean of all the measurements & the most recently observed point\n",
    "            'SBP_mean', 'SBP_recent',\n",
    "            'MAP_mean', 'MAP_recent', # mean arterial pressure\n",
    "             'temp_mean', 'temp_recent',# temperature\n",
    "             'SPO2_mean', 'SPO2_recent',\n",
    "            'RR_mean', 'RR_recent', # respiratory rate\n",
    "            'pulse_mean', 'pulse_recent']\n",
    "\n",
    "# Which rows are all nans?\n",
    "\n",
    "print np.where(X1.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]\n",
    "print np.where(X2.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]\n",
    "print np.where(X3.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Oh good, they're all the same samples. let's get rid of those rows.\n",
    "# Write out rows that are not all 0/NaNs across. (if all nans, remove this sample)\n",
    "X1 = X1.loc[np.where(X1.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]]; X1 = X1.reset_index(drop=True)\n",
    "X2 = X2.loc[np.where(X2.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]]; X2 = X2.reset_index(drop=True)\n",
    "X3 = X3.loc[np.where(X3.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]]; X3 = X3.reset_index(drop=True)\n",
    "\n",
    "# if 'obese' is Nan, then set the patient to be not obese.\n",
    "X1.loc[np.where(pd.isnull(X1['obese']))[0], 'obese'] = 0\n",
    "X2.loc[np.where(pd.isnull(X2['obese']))[0], 'obese'] = 0\n",
    "X3.loc[np.where(pd.isnull(X3['obese']))[0], 'obese'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## some entries for temperature & pulse are nan. Let's fill those values, using the mean from the column.\n",
    "# Fill nans with mean of columns\n",
    "X1 = X1.fillna(X1.mean())\n",
    "X2 = X2.fillna(X2.mean())\n",
    "X3 = X3.fillna(X3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load saved model\n",
    "# from sklearn.externals import joblib\n",
    "gbc = joblib.load('my_trained_model.compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred1 = gbc.predict_proba(X1)\n",
    "ypred2 = gbc.predict_proba(X2)\n",
    "ypred3 = gbc.predict_proba(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs1 = pd.DataFrame(data=ypred1[:,1], columns =[\"model_probability_of_rrt\"])\n",
    "pred_probs1['model_probability_of_rrt'] = pd.to_numeric(pred_probs1.model_probability_of_rrt)\n",
    "pred_probs1['score'] = pred_probs1['model_probability_of_rrt'].apply(lambda x: int(round(x*10.0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_probs2 = pd.DataFrame(data=ypred2[:,1], columns =[\"model_probability_of_rrt\"])\n",
    "pred_probs2['model_probability_of_rrt'] = pd.to_numeric(pred_probs2.model_probability_of_rrt)\n",
    "pred_probs2['score'] = pred_probs2['model_probability_of_rrt'].apply(lambda x: int(round(x*10.0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_probs3 = pd.DataFrame(data=ypred3[:,1], columns =[\"model_probability_of_rrt\"])\n",
    "pred_probs3['model_probability_of_rrt'] = pd.to_numeric(pred_probs3.model_probability_of_rrt)\n",
    "pred_probs3['score'] = pred_probs3['model_probability_of_rrt'].apply(lambda x: int(round(x*10.0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc1 = modeltable1.iloc[np.where(modeltable1.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0],:]['encntr_id']\n",
    "enc1 = enc1.reset_index(drop=True)\n",
    "enc2 = modeltable2.iloc[np.where(modeltable2.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0],:]['encntr_id']\n",
    "enc2 = enc2.reset_index(drop=True)\n",
    "enc3 = modeltable3.iloc[np.where(modeltable3.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0],:]['encntr_id']\n",
    "enc3 = enc3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.concat([enc1, X1, pred_probs1],axis=1)\n",
    "df2 = pd.concat([enc2, X2, pred_probs2],axis=1)\n",
    "df3 = pd.concat([enc3, X3, pred_probs3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# May need to rename columns to get rid of dash in name...\n",
    "df1.rename(columns={'bu-nal': 'bu_nal', 'narc-ans': 'narc_ans'}, inplace=True)\n",
    "df2.rename(columns={'bu-nal': 'bu_nal', 'narc-ans': 'narc_ans'}, inplace=True)\n",
    "df3.rename(columns={'bu-nal': 'bu_nal', 'narc-ans': 'narc_ans'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close previous impyla connection, reconnect on ibis...\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use ibis to save dfs to HDFS\n",
    "import ibis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdfs = ibis.hdfs_connect(host=\"mycluster.domain.com\")\n",
    "con = ibis.impala.connect(host=\"mycluster.domain.com\", port=my_impala_port_number, hdfs_client=hdfs)\n",
    "db = con.database('my_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.create_table('sxamplePatientsScores_0_12hrs', df1)\n",
    "t = db.examplePatientsScores_0_12hrs\n",
    "t.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.create_table('examplePatientsScores_12_24hrs', df2)\n",
    "t = db.examplePatientsScores_12_24hrs\n",
    "t.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.create_table('examplePatientsScores_24_36hrs', df3)\n",
    "t = db.examplePatientsScores_24_36hrs\n",
    "t.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
