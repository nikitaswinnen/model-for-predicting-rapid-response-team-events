{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goes over modeling, starting from modeling tables.\n",
    "### We're using modeling tables which were prepared based on 12 hours worth of vital sign data from each patient, as well as medication history during the stay, and patient characteristics.\n",
    "### The model predicts the probability of having a rapid response team event in 1 hour's time from the time of prediction. A RRT event is called after personnel identify that a patient has an urgent need for medical service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "# import datetime as datetime\n",
    "import cPickle as pickle\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier #, RandomForestClassifier, \n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence, partial_dependence\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_printout(X_test, y_test, fittedModel):\n",
    "    print \"AUC-ROC Score of model: \", roc_auc_score(y_test, fittedModel.predict_proba(X_test)[:,1])\n",
    "    print \"Precision Score of model: \", precision_score(y_test, fittedModel.predict(X_test))\n",
    "    print \"Recall Score of model: \", recall_score(y_test, fittedModel.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feature_importance_plot(featuresAndImportances, numFeatures):\n",
    "    topN = featuresAndImportances[:numFeatures]\n",
    "    labels = [pair[0] for pair in topN]\n",
    "    values = [pair[1] for pair in topN]\n",
    "    ind = np.arange(len(values)+2)\n",
    "    width = 0.35   \n",
    "    plt.barh(range(numFeatures),values)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_yticks(ind+width)\n",
    "    ax.set_yticklabels(labels, rotation=0, size=12)\n",
    "    plt.ylabel('Feature', size=20)\n",
    "    plt.xlabel('Importance', size=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "We did not share our modeling data, so you will have to create your own. The pipeline tool can help you do this. If you save the results to a csv, `masterdf_rrt` and `masterdf_nonrrt` are dataframes with the modeling data for each of the positive and negative classes, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masterdf_rrt = pd.read_csv('RRT_modeling_table_13hr_raw.csv')\n",
    "masterdf_nonrrt = pd.read_csv('NonRRT_modeling_table_13hr_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at summary statistics for numeric columns for rrt & non-rrt tables (35 cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masterdf_rrt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masterdf_rrt.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masterdf_nonrrt.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a good amount of nan values in some columns. Lets plot the nan values to get a sense of how many there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_df_nans(masterdf, collist=None):\n",
    "    '''\n",
    "    Create a data frame for features which may be nan.\n",
    "    Make nan values be 1, numeric values be 0\n",
    "    A heat map where dark squares/lines show where data is missing.\n",
    "    '''\n",
    "    if not collist:\n",
    "        plot_cols = ['obese','DBP_mean', 'DBP_recent', 'SBP_mean', 'SBP_recent', 'HR_mean', 'HR_recent',\n",
    "               'MAP_mean', 'MAP_recent', 'temp_mean', 'temp_recent', 'SPO2_mean',\n",
    "               'SPO2_recent', 'RR_mean', 'RR_recent', 'pulse_mean', 'pulse_recent',\n",
    "               'CO2_mean', 'CO2_recent', 'GCS_mean', 'GCS_recent']\n",
    "    else:\n",
    "        plot_cols = collist \n",
    "    \n",
    "    df_viznan = pd.DataFrame(data = 1,index=masterdf.index,columns=plot_cols)\n",
    "    df_viznan[~pd.isnull(masterdf[plot_cols])] = 0\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title('Dark values are nans')\n",
    "    return sns.heatmap(df_viznan.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset of numeric columns we'll use in modeling (sufficient data available)\n",
    "plot_cols_good = ['obese','DBP_mean', 'DBP_recent', 'SBP_mean', 'SBP_recent', \n",
    "               'MAP_mean', 'MAP_recent', 'temp_mean', 'temp_recent', 'SPO2_mean',\n",
    "               'SPO2_recent', 'RR_mean', 'RR_recent', 'pulse_mean', 'pulse_recent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_df_nans(masterdf_nonrrt)  # show all columns that may have nans\n",
    "# show_df_nans(masterdf_nonrrt, plot_cols_good)  # show the columns whch we plan to use for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_df_nans(masterdf_rrt)\n",
    "# show_df_nans(masterdf_rrt, plot_cols_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Let's not use those columns where there are significant nans: drop HR (heart rate; we have pulse rate instead), CO2, and GCS, which leaves us with 28 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_use = ['age', 'sex', 'obese', 'smoker', 'prev_rrt', 'on_iv', 'bu-nal', 'DBP_mean',\n",
    "       'DBP_recent', 'SBP_mean', 'SBP_recent',\n",
    "       'MAP_mean', 'MAP_recent', 'temp_mean', 'temp_recent', 'SPO2_mean',\n",
    "       'SPO2_recent', 'RR_mean', 'RR_recent', 'pulse_mean', 'pulse_recent',\n",
    "       'anticoagulants', 'narcotics', 'narc-ans', 'antipsychotics',\n",
    "       'chemo', 'dialysis', 'race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_rrt = masterdf_rrt[col_use]\n",
    "X_notrrt = masterdf_nonrrt[col_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We need to deal with these nans before we can start modeling. (There should not be any nans in the modeling table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's look at getting rid of the data rows where vitals signs are all nans\n",
    "vitals_cols = ['DBP_mean', 'DBP_recent', # take the mean of all the measurements & the most recently observed point\n",
    "            'SBP_mean', 'SBP_recent',\n",
    "            'MAP_mean', 'MAP_recent', # mean arterial pressure\n",
    "             'temp_mean', 'temp_recent',# temperature\n",
    "             'SPO2_mean', 'SPO2_recent',\n",
    "            'RR_mean', 'RR_recent', # respiratory rate\n",
    "            'pulse_mean', 'pulse_recent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write out rows that are not all 0/NaNs across. (if all nans, remove this sample)\n",
    "X_rrt = X_rrt.loc[np.where(X_rrt.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]]\n",
    "X_rrt = X_rrt.reset_index(drop=True)\n",
    "X_notrrt = X_notrrt.loc[np.where(X_notrrt.ix[:, vitals_cols].sum(axis=1, skipna=True)!=0)[0]]\n",
    "X_notrrt = X_notrrt.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if 'obese' is Nan, then set the patient to be not obese.\n",
    "X_rrt.loc[np.where(pd.isnull(X_rrt['obese']))[0], 'obese'] = 0\n",
    "X_notrrt.loc[np.where(pd.isnull(X_notrrt['obese']))[0], 'obese'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how X_rrt & X_notrrt look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_df_nans(X_rrt, vitals_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_df_nans(X_notrrt, vitals_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some columns have significant missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_rrt[['pulse_mean', 'pulse_recent']].describe().T\n",
    "print \"size of X_rrt: \"+str(len(X_rrt))\n",
    "print\n",
    "print X_notrrt[['pulse_mean', 'pulse_recent']].describe().T\n",
    "print \"size of X_notrrt: \" + str(len(X_notrrt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have plenty of samples for the non-RRT case. We can delete off rows with values that are missing without concern that we'll lose negtive examples for RRT events for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DROP THE ROWS WHERE PULSE IS NAN\n",
    "X_notrrt = X_notrrt.ix[np.where(pd.isnull(X_notrrt['pulse_mean'])!=True)[0]]\n",
    "X_notrrt = X_notrrt.reset_index(drop=True)\n",
    "# And similarly for all rows with significant nans:\n",
    "X_notrrt = X_notrrt.ix[np.where(pd.isnull(X_notrrt['RR_mean'])!=True)[0]]\n",
    "X_notrrt = X_notrrt.reset_index(drop=True)\n",
    "X_notrrt = X_notrrt.ix[np.where(pd.isnull(X_notrrt['MAP_mean'])!=True)[0]]\n",
    "X_notrrt = X_notrrt.reset_index(drop=True)\n",
    "X_notrrt = X_notrrt.ix[np.where(pd.isnull(X_notrrt['temp_mean'])!=True)[0]]\n",
    "X_notrrt = X_notrrt.reset_index(drop=True)\n",
    "X_notrrt = X_notrrt.ix[np.where(pd.isnull(X_notrrt['SPO2_mean'])!=True)[0]]\n",
    "X_notrrt = X_notrrt.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cols = ['age', 'sex', 'obese', 'smoker', 'prev_rrt', 'on_iv', 'bu-nal',\n",
    "       'DBP_mean', 'DBP_recent', 'SBP_mean', 'SBP_recent', 'MAP_mean',\n",
    "       'MAP_recent', 'temp_mean', 'temp_recent', 'SPO2_mean',\n",
    "       'SPO2_recent', 'RR_mean', 'RR_recent', 'pulse_mean', 'pulse_recent',\n",
    "       'anticoagulants', 'narcotics', 'narc-ans', 'antipsychotics',\n",
    "       'chemo', 'dialysis', 'race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_df_nans(X_notrrt, all_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still need to deal with nans in X_rrt. Temp & pulse are the most of concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_rrt[['temp_mean', 'pulse_mean']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll impute missing values in X_rrt after combining that data with X_notrrt, and use the mean from each column after merging to fill the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add labels to indicate positive or negative class\n",
    "X_rrt['label'] = 1\n",
    "X_notrrt['label'] = 0\n",
    "\n",
    "# Combine the tables\n",
    "XY = pd.concat([X_rrt, X_notrrt])\n",
    "XY = XY.reset_index(drop=True)\n",
    "y = XY.pop('label')\n",
    "X = XY\n",
    "\n",
    "# Fill nans with mean of columns\n",
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map genders to 1/0\n",
    "X['is_male'] = X['sex'].map({'M': 1, 'F': 0})\n",
    "X.pop('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we won't use race in modeling\n",
    "X.pop('race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_df_nans(X, vitals_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(y_train)\n",
    "print len(y_train[y_train]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_test[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xscaled = StandardScaler().fit_transform(X)\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xscaled, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier - Unscaled (with partial dependence plots below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramGrid = {'n_estimators': [100, 200, 300],\n",
    "             'learning_rate': [0.1, 0.05, 0.01, 0.2],\n",
    "             'max_depth': [3, 4, 5, 6],\n",
    "             'min_samples_leaf': [1, 2],\n",
    "             'subsample': [0.75, 1.0, 0.85],\n",
    "             'loss': ['deviance'],\n",
    "             'max_features': [None, 'auto']\n",
    "            }\n",
    "\n",
    "gs = GridSearchCV(GradientBoostingClassifier(), \n",
    "                  param_grid=paramGrid, \n",
    "                  scoring='roc_auc', \n",
    "                  n_jobs=-1, \n",
    "                  cv=5, \n",
    "                  verbose=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Result:\n",
    "# GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
    "#               max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "#               min_samples_leaf=2, min_samples_split=2,\n",
    "#               min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "#               presort='auto', random_state=None, subsample=0.75, verbose=0,\n",
    "#               warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for best GBC - Scaled (with partial dependece plots below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paramGrid = {'n_estimators': [100, 200, 300],\n",
    "             'learning_rate': [0.1, 0.05, 0.01, 0.2],\n",
    "             'max_depth': [3, 4, 5, 6],\n",
    "             'min_samples_leaf': [1, 2],\n",
    "             'subsample': [0.75, 1.0, 0.85],\n",
    "             'loss': ['deviance'],\n",
    "             'max_features': [None, 'auto']\n",
    "            }\n",
    "\n",
    "gss = GridSearchCV(GradientBoostingClassifier(), \n",
    "                  param_grid=paramGrid, \n",
    "                  scoring='roc_auc', \n",
    "                  n_jobs=-1, \n",
    "                  cv=5, \n",
    "                  verbose=10)\n",
    "\n",
    "gss.fit(Xs_train, ys_train)\n",
    "\n",
    "# Result:\n",
    "# GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
    "#               max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
    "#               min_samples_leaf=1, min_samples_split=2,\n",
    "#               min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "#               presort='auto', random_state=None, subsample=0.75, verbose=0,\n",
    "#               warm_start=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How different are best estimators for scaled & unscaled data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
    "               max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "               min_samples_leaf=2, min_samples_split=2,\n",
    "               min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "               presort='auto', random_state=None, subsample=0.75, verbose=0,\n",
    "               warm_start=False)\n",
    "gbc.fit(X_train, y_train)\n",
    "score_printout(X_test, y_test, gbc)\n",
    "print classification_report(y_test, gbc.predict(X_test))\n",
    "confusion_matrix(y_test, gbc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gbcs = gss.best_estimator_\n",
    "# gbcs.fit(Xs_train, ys_train)\n",
    "# score_printout(Xs_test, ys_test, gbc)\n",
    "# print classification_report(ys_test, gbcs.predict(Xs_test))\n",
    "# confusion_matrix(ys_test, gbcs.predict(Xs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use unscaled data -- better results & easier interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the confusion matrix so it's a little clearer\n",
    "plt.figure()\n",
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(confusion_matrix(y_test, gbc.predict(X_test)), annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the most important features in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbcRankedFeatures = sorted(zip(X.columns, gbc.feature_importances_), \n",
    "                          key=lambda pair: pair[1], \n",
    "                          reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "make_feature_importance_plot(gbcRankedFeatures, 27) # note - we have 27 features currently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Let's look a partial dependence plots\n",
    "#### If the partial dependence is high, then the model for that given value of that given feature is more likely to predict an rrt result.\n",
    "#### Will not show more complex interactions -- if importance is high but partial dependence is marginal, this may be due to interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_partial_dependence(gbc, X_train, range(0, 6, 1), feature_names=X.columns.get_values(), n_jobs=-1, grid_resolution=50)\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_partial_dependence(gbc, X_train, range(6, 12, 1), feature_names=X.columns.get_values(), n_jobs=-1, grid_resolution=50)\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_partial_dependence(gbc, X_train, range(12, 18, 1), feature_names=X.columns.get_values(), n_jobs=-1, grid_resolution=50)\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_partial_dependence(gbc, X_train, range(18, 24, 1), feature_names=X.columns.get_values(), n_jobs=-1, grid_resolution=50)\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_partial_dependence(gbc, X_train, range(24, 27, 1), feature_names=X.columns.get_values(), n_jobs=-1, grid_resolution=50)\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use 3-D plot to investigate feature interactions for weak partial dependence plots... (weak effect may be masked by stronger interaction with other features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = X_train.columns\n",
    "zip(range(len(names)), names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not all features may work for this viz\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "target_feature = (16, 18)  # <--  change the two numbers here to determine what to plot up\n",
    "pdp, (x_axis, y_axis) = partial_dependence(gbc, target_feature, X=X_train, grid_resolution=50)\n",
    "XX, YY = np.meshgrid(x_axis, y_axis)\n",
    "Z = pdp.T.reshape(XX.shape).T\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(XX, YY, Z, rstride=1, cstride=1, cmap=plt.cm.BuPu)\n",
    "ax.set_xlabel(names[target_feature[0]])\n",
    "ax.set_ylabel(names[target_feature[1]])\n",
    "ax.set_zlabel('Partial dependence')\n",
    "#  pretty init view\n",
    "ax.view_init(elev=22, azim=122)\n",
    "plt.colorbar(surf)\n",
    "plt.suptitle('')\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Model to Risk Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return probabilities from the model, rather than predictions\n",
    "y_proba = gbc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# note - y_proba contains probabilities for class 0 in column 0 & probabilities for class 1 in column 1.\n",
    "# we're only interested in the probability for class 1\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs = pd.DataFrame(data=y_proba[:,1], columns =[\"model_probability_of_rrt\"], index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_probs['model_probability_of_rrt'] = pd.to_numeric(pred_probs.model_probability_of_rrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs.hist(bins = 20, xlabelsize = 16, ylabelsize=16)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.title(\"Model output probabilities\")\n",
    "plt.ylabel('Count', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We see that although we see more values close to 0 and 1, we also see that the model outputs a full range of probabilities, which would translate well into risk scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Patient Risk Score = model probability * 10\n",
    "The score should be rounded to whole values to give the sense that this is not an exact measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs['score'] = pred_probs['model_probability_of_rrt'].apply(lambda x: int(round(x*10.0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_probs.score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# joblib.dump(gbc, 'gbc_base.pkl') # note - if left uncompressed, this writes a whole lot of supporting numpy files.\n",
    "joblib.dump(gbc, 'my_trained_model.compressed', compress=True)  \n",
    "\n",
    "# to unpack: joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save modeling table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create combined data frame including modeling table, rrt label, and proability associated with result\n",
    "df = pd.concat([X_test, pred_probs, y_test],axis=1, join_axes=[X_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# May need to rename columns to get rid of dash in name...\n",
    "df.rename(columns={'bu-nal': 'bu_nal', 'narc-ans': 'narc_ans'}, inplace=True)\n",
    "df.to_csv('ModelingTable_with_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
